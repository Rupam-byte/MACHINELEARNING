{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2656211-9593-466f-afa9-1114ab9bde0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import kagglehub\n",
    "\n",
    "# Download dataset\n",
    "path = kagglehub.dataset_download(\"hijest/genre-classification-dataset-imdb\")\n",
    "print(\" Dataset downloaded at:\", path)\n",
    "\n",
    "# Check contents of the main folder\n",
    "print(\" Main folder contents:\", os.listdir(path))\n",
    "\n",
    "# Look inside subfolders for CSV\n",
    "csv_file = None\n",
    "for root, dirs, files in os.walk(path):\n",
    "    for f in files:\n",
    "        if f.endswith(\".csv\") or f.endswith(\".txt\"):\n",
    "            csv_file = os.path.join(root, f)\n",
    "            break\n",
    "    if csv_file:\n",
    "        break\n",
    "\n",
    "if not csv_file:\n",
    "    raise FileNotFoundError(\"No CSV/TXT file found in the dataset folder or subfolders.\")\n",
    "\n",
    "print(\" Loading dataset from:\", csv_file)\n",
    "df = pd.read_csv(csv_file)\n",
    "\n",
    "print(\" Dataset loaded successfully!\")\n",
    "print(df)\n",
    "print(\"Shape:\", df.shape)\n",
    "print(df.head())\n",
    "\n",
    "\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"wordnet\")\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "\n",
    "def preprocess_text(text):\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    tokens = text.split()\n",
    "    tokens = [t for t in tokens if t.isalpha() and t.lower() not in stop_words]\n",
    "    tokens = [lemmatizer.lemmatize(t.lower()) for t in tokens]\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "# Split the column into separate columns\n",
    "df = df.iloc[:,0].str.split(' ::: ', expand=True)\n",
    "df.columns = ['ID', 'TITLE', 'GENRE', 'DESCRIPTION']\n",
    "\n",
    "print(\"ðŸ§¹ Cleaning text data...\")\n",
    "df[\"DESCRIPTION\"] = df[\"DESCRIPTION\"].apply(preprocess_text)\n",
    "\n",
    "# 3. Remove Rare Genres\n",
    "genre_counts = df[\"GENRE\"].value_counts()\n",
    "df = df[df[\"GENRE\"].isin(genre_counts[genre_counts > 1].index)]\n",
    "print(\" Rare genres removed.\")\n",
    "print(\"Remaining unique genres:\", df[\"GENRE\"].nunique())\n",
    "\n",
    "# 4. Encode Genre Labels\n",
    "le = LabelEncoder()\n",
    "df[\"GENRE\"] = le.fit_transform(df[\"GENRE\"].astype(str))\n",
    "print(\"Encoded genre count:\", len(le.classes_))\n",
    "\n",
    "# 5. Train-Test Split\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    df[\"DESCRIPTION\"],\n",
    "    df[\"GENRE\"],\n",
    "    test_size=0.2,\n",
    "    random_state=76\n",
    ")\n",
    "\n",
    "# 6. TF-IDF Vectorization\n",
    "vectorizer = TfidfVectorizer(max_features=5000, binary=True, ngram_range=(1,2))\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_val_tfidf = vectorizer.transform(X_val)\n",
    "\n",
    "print(\" TF-IDF vectorization complete.\")\n",
    "print(\"Feature matrix shape:\", X_train_tfidf.shape)\n",
    "\n",
    "\n",
    "print(\"Naive Bayes\", BernoulliNB())\n",
    "print(\"Logistic Regression\", LogisticRegression(max_iter=1000))\n",
    "print(\"Support Vector Machine\", LinearSVC())\n",
    "\n",
    "results = {}\n",
    "\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nðŸš€ Training {name}...\")\n",
    "    model.fit(X_train_tfidf, y_train)\n",
    "    y_pred = model.predict(X_val_tfidf)\n",
    "    acc = accuracy_score(y_val, y_pred)\n",
    "    results[name] = acc\n",
    "    print(f\" {name} Accuracy: {acc:.4f}\")\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_val, y_pred, zero_division=0))\n",
    "\n",
    "# 8. Compare Models\n",
    "print(\"\\n Model Comparison:\")\n",
    "for model_name, acc in results.items():\n",
    "    print(f\"{model_name}: {acc:.4f}\")\n",
    "\n",
    "best_model_name = max(results, key=results.get)\n",
    "print(f\"\\n Best Model: {best_model_name} (Accuracy: {results[best_model_name]:.4f})\")\n",
    "\n",
    "# --------------------------------------------\n",
    "# 9. Save Best Model, Vectorizer, Encoder\n",
    "# --------------------------------------------\n",
    "best_model = models[best_model_name]\n",
    "joblib.dump(best_model, \"best_genre_model.pkl\")\n",
    "joblib.dump(vectorizer, \"tfidf_vectorizer.pkl\")\n",
    "joblib.dump(le, \"label_encoder.pkl\")\n",
    "print(\"\\n Model, vectorizer, and label encoder saved successfully!\")\n",
    "\n",
    "# 10. Predict Genre for New Plot Summary\n",
    "def predict_genre(plot_summary):\n",
    "    text = preprocess_text(plot_summary)\n",
    "    X_input = vectorizer.transform([text])\n",
    "    pred = best_model.predict(X_input)\n",
    "    genre = le.inverse_transform(pred)[0]\n",
    "    return genre\n",
    "\n",
    "example_plot = \"A young boy discovers he is a wizard and attends a magical school to learn spells.\"\n",
    "predicted_genre = predict_genre(example_plot)\n",
    "print(\"\\n Example Prediction:\")\n",
    "print(f\"Plot: {example_plot}\")\n",
    "print(f\"Predicted Genre: {predicted_genre}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
